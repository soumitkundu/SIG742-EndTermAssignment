{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNL5NYYXiCC9CSHll6VTdKJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumitkundu/SIG742-EndTermAssignment/blob/main/SIG742Task2-Group-13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Student ID:** _225738919_\n",
        "\n",
        "**Student Name:** _Soumit Kundu_\n",
        "\n",
        "**Workshop / Lab Session Time:** Mon / Tue / Wed / Thu / Fri"
      ],
      "metadata": {
        "id": "caXaUH9eRJBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: **Data Acquisition and Manipulation**"
      ],
      "metadata": {
        "id": "yMIVXppXR7Wy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The (business_review_submission.zip) data used for this part could be found in [here](https://github.com/tulip-lab/sit742/blob/develop/Jupyter/data/business_review_submission.zip). There are two files in the data. The first one is about the business review submission with many companies. For each of the row, the review submission is provided with relevant information such as user id, time, name and many others. The second one is the meta information of the business and the two data could be joined with gmap_id. You will need to use spark to **first read the unzipped (csv) review data for starting** and later join the meta review business data on dataframe (pandas or spark). You could find the code on reading csv data with Spark from [M04G](https://github.com/tulip-lab/sit742/blob/develop/Jupyter/M04-DataManipulation/M04G-SparkSQL.ipynb). In some of the tasks, if the question is not specifically asking to use spark, you could use both pandas and numpy."
      ],
      "metadata": {
        "id": "cQm6tOhDSku-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 1.1"
      ],
      "metadata": {
        "id": "ToQj2ngBSISG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**\n",
        "\n",
        "Using PySpark to do some data wrangling process, so that:\n",
        "> **1.1.1** For the none or null in text column, change it to 'no review'.\n",
        "\n",
        "> **1.1.2** Process the content in time column, and convert the strings from time to yyyy-mm-dd format in the new column as newtime and show the first 5 rows."
      ],
      "metadata": {
        "id": "LIMKq0ekSTRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing Required Libraries**"
      ],
      "metadata": {
        "id": "IL6c6HkhIy04"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DWV9cf_PQmZj",
        "outputId": "7cb4fa7f-613e-4273-f250-57f559c07c4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "\r                                                                               \rGet:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [3 InRelease 127 kB/127 kB 100%] [Connected to cloud.r-project.org (65.9.86.\r0% [Connected to cloud.r-project.org (65.9.86.28)] [Connected to r2u.stat.illin\r                                                                               \rGet:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [5 InRelease 0 B/3,632 B 0%] [Connected to r2u.stat.illinois.edu (192.17.190\r0% [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers] \r                                                                               \rHit:6 https://cli.github.com/packages stable InRelease\n",
            "\r0% [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers] \r                                                                               \rGet:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Connected to r2u.stat.illinois.edu (192.17.190.167)] [7 InRelease 1,581 B/1\r                                                                               \r0% [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers]\r                                                                              \rHit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "\r                                                                              \r0% [Connected to r2u.stat.illinois.edu (192.17.190.167)]\r                                                        \rHit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,690 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,577 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,274 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,609 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,371 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Get:18 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [81.0 kB]\n",
            "Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,014 kB]\n",
            "Get:20 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,307 kB]\n",
            "Get:21 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,807 kB]\n",
            "Fetched 30.2 MB in 5s (6,031 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ],
      "source": [
        "#update local version of the package catalog\n",
        "!apt-get update\n",
        "# install Java8\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# download spark 3.3.3\n",
        "# !wget -q https://archive.apache.org/dist/spark/spark-3.3.3/spark-3.3.3-bin-hadoop3.tgz\n",
        "# # unzip it\n",
        "# !tar xf spark-3.3.3-bin-hadoop3.tgz\n",
        "# install findspark\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "YW3Ze7uLT47r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "6yhYyHyfeKKW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "pyspark.__version__"
      ],
      "metadata": {
        "id": "ARirSomSepoB",
        "outputId": "8355f493-ebcc-402c-9b6f-3c01d61cd038",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.5.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyspark import SparkContext\n",
        "# from pyspark.sql import SQLContext\n",
        "\n",
        "# # Initialize SparkContext\n",
        "# sc = SparkContext.getOrCreate()\n",
        "\n",
        "# #SQLContext is the entry point for working with structured data (rows and columns) in Spark, in Spark 1.x.\n",
        "# #As of Spark 2.0, this is replaced by SparkSession.\n",
        "# #However, we are keeping the class here for backward compatibility.\n",
        "# #A SQLContext can be used create DataFrame, register DataFrame as tables, execute SQL over tables, cache tables, and read parquet files\n",
        "# sqlContext = SQLContext(sc)"
      ],
      "metadata": {
        "id": "jroi585hT45a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing SparkSession as our pyspark version is updated\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initializing SparkSession and crearing the app\n",
        "spark = SparkSession.builder.appName('SIG742').getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "id": "WbMMuLC_gIwJ",
        "outputId": "cf6c5003-46c6-47e7-c0bb-ce4f40e4fc42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7849cc6bb500>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c3bc6a83baf3:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>SIG742</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connect to google colab drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "# Initializing folder path where our datasets are stored\n",
        "drive_path = '/content/gdrive/MyDrive/MDS-Datasets/SIG742/business_review_submission'"
      ],
      "metadata": {
        "id": "sVfQbeOJT42g",
        "outputId": "e715175f-b846-4534-8811-b9fa91379e81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Returns a DataFrameReader that can be used to read data in as a DataFrame.\n",
        "# df_review = sqlContext.read.csv(drive_path + \"/review.csv\", header=True)\n",
        "# df_review"
      ],
      "metadata": {
        "id": "CXqOXSJqJfRa",
        "outputId": "20b4a7ae-f5d7-44c7-d130-612865475cda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame[user_id: string, name: string, time: string, rating: string, text: string, pics: string, resp: string, gmap_id: string]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_review = spark.read.csv(drive_path + \"/review.csv\", header=True)\n",
        "df_review"
      ],
      "metadata": {
        "id": "a2X9P6rthWDK",
        "outputId": "49ac73ca-cdf9-4488-9e57-c03e2b31136f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[user_id: string, name: string, time: string, rating: string, text: string, pics: string, resp: string, gmap_id: string]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_review.show(5)"
      ],
      "metadata": {
        "id": "hD7Cj_htJfOS",
        "outputId": "b2955554-627e-4c17-81ca-ff98a885b4cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-------------+--------------------+--------------------+----+----+--------------------+\n",
            "|             user_id|                name|         time|              rating|                text|pics|resp|             gmap_id|\n",
            "+--------------------+--------------------+-------------+--------------------+--------------------+----+----+--------------------+\n",
            "|1.091298048426862...|          Nicki Gore|1566331951619|                   5|We always stay he...|NULL|NULL|0x56b646ed2220b77...|\n",
            "|1.132409264057589...|       Allen Ratliff|1504917982385|                   5|Great campground ...|NULL|NULL|0x56b646ed2220b77...|\n",
            "|1.130448378911412...|   Jonathan Tringali|1474765901185|                   4|We tent camped he...|NULL|NULL|                NULL|\n",
            "|There is a bath h...| 2 restrooms (sin...|       toilet| shower). The hot...| but they lack ve...|NULL|NULL|                NULL|\n",
            "|Wi-Fi didn't reac...|                NULL|         NULL|0x56b646ed2220b77...|                NULL|NULL|NULL|                NULL|\n",
            "+--------------------+--------------------+-------------+--------------------+--------------------+----+----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing spark sql functions\n",
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "2DM9pI7niI14"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1.1** For the none or null in text column, change it to 'no review'."
      ],
      "metadata": {
        "id": "oeBZ5R6kjHCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "null_review_count = df_review.filter(col('text').isNull()).count()\n",
        "print(f\"None or Null count for text column is {null_review_count}\")"
      ],
      "metadata": {
        "id": "BTfM7QcziZa7",
        "outputId": "ad06dccd-b7da-41ab-880f-ed2055615f39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None or Null count for text column is 249931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_review_filtered = df_review.fillna('no review', subset=['text'])"
      ],
      "metadata": {
        "id": "LZTt0I-eiWU1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_review_count = df_review_filtered.filter(df_review_filtered['text'] == 'no review').count()\n",
        "no_review_count"
      ],
      "metadata": {
        "id": "GPl3RXwTJfGl",
        "outputId": "83873d16-9c48-4ee5-928b-f2afa48d35f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "249931"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CyVBcinojS-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1.2** Process the content in time column, and convert the strings from time to yyyy-mm-dd format in the new column as newtime and show the first 5 rows."
      ],
      "metadata": {
        "id": "cNIKQ-M7jUvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_converted = df_review_filtered.withColumn(\n",
        "    'newtime',\n",
        "    to_date(from_unixtime(col('time').cast('bigint') / 1000))\n",
        ")\n",
        "df_converted.show(5)"
      ],
      "metadata": {
        "id": "pr93qGW9T4zv",
        "outputId": "abb95479-5e55-4699-8cb2-95f60534958d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-------------+--------------------+--------------------+----+----+--------------------+----------+\n",
            "|             user_id|                name|         time|              rating|                text|pics|resp|             gmap_id|   newtime|\n",
            "+--------------------+--------------------+-------------+--------------------+--------------------+----+----+--------------------+----------+\n",
            "|1.091298048426862...|          Nicki Gore|1566331951619|                   5|We always stay he...|NULL|NULL|0x56b646ed2220b77...|2019-08-20|\n",
            "|1.132409264057589...|       Allen Ratliff|1504917982385|                   5|Great campground ...|NULL|NULL|0x56b646ed2220b77...|2017-09-09|\n",
            "|1.130448378911412...|   Jonathan Tringali|1474765901185|                   4|We tent camped he...|NULL|NULL|                NULL|2016-09-25|\n",
            "|There is a bath h...| 2 restrooms (sin...|       toilet| shower). The hot...| but they lack ve...|NULL|NULL|                NULL|      NULL|\n",
            "|Wi-Fi didn't reac...|                NULL|         NULL|0x56b646ed2220b77...|           no review|NULL|NULL|                NULL|      NULL|\n",
            "+--------------------+--------------------+-------------+--------------------+--------------------+----+----+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4p0IXPfVktyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 1.2"
      ],
      "metadata": {
        "id": "Zdk8ZJ8YT5i1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**\n",
        "\n",
        "Find out the information for gmap_id on the reviews. In order to achieve the above, some wrangling work is required to be done:\n",
        "> **1.2.1** Using pyspark to calculate the number of reviews per each unique gmap_id and save as float format in pyspark dataframe to show the top 5 rows.\n",
        "\n",
        "> **1.2.2** Transform the current pyspark dataframe to pandas dataframe (named as df) and create the column reivew_time with the information of review time on hours level. Print your df pandas dataframe with top 5 rows after creating the column review_time.\n",
        "\n",
        "> **1.2.3** Using matplotlib or seaborn to draw some (two or more if possible) visualizations on the relationship between gmap_id and reivew_time. You could explore for example, what is the time people usually review? How many business is reviewed in the morning time etc. Please also discuss the insights you are finding with your visualizations in the markdown cell. Please also include your findings and visualizations in the report."
      ],
      "metadata": {
        "id": "inEfSH71T9SO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qbmZTRsDT8W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tGjKz6h0fIaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "roX_GiQqfIXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DCQ8TjM3fIMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nkDDDNRVfIJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3pzbHBFofIGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 1.3"
      ],
      "metadata": {
        "id": "XoUbTxLHfL0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**\n",
        "\n",
        "Let’s continue to analyze the reivew_time with reviews and related gmap_id. You need to use another data meta-business to join with the current dataframe on gmap_id.\n",
        "> **1.3.1** Determine which workday (day of the week), generates the most reviews (plotting the results in a line chart with workday on averaged submissions).\n",
        "\n",
        "> **1.3.2** Identify the names of business (column name from data meta-business) that has the highest averaged ratings on ‘that workday’ (you need to find out from 1.3.1), and find out which category those businesses are from?\n",
        "\n",
        "> **1.3.3** Please further explore the data on name of business and find out some more insights by yourself such as which category it is and what are the peak hours etc. Please use visualizations and tables to support your findings and write down the insights in the markdown cell. Please also include your findings and visualizations in the report."
      ],
      "metadata": {
        "id": "QyzRijEefUtM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R75yKe8UfQ2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fFjgYYtAfrb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nivgpjAWfsP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b3RFJE4ZfsMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "244HsBvSfsJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ReMjpClnftDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pu6jAF6Wft6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 1.4"
      ],
      "metadata": {
        "id": "JmwCYqotfufx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**\n",
        "\n",
        "For the reviews on each of the submissions, work on all the review content and find out the top 30 most common words; Also generate separate word cloud visualizations for different years by grouping the reviews by review year and write down the insights in the markdown cell. Please also include your findings and visualizations in the report."
      ],
      "metadata": {
        "id": "WGTlIe-gfy8t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PrdMxMGQftAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9xT33vjVf5UG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XcHGQ1bvf5RC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-ByM8FrQf5No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dlA2ax8-f5KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g1PsWxP5f6M2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 1.5"
      ],
      "metadata": {
        "id": "L83Nns1df6vY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**\n",
        "\n",
        "Let’s do some analysis on the business_name and the reviewers. Determine the number of unique reviewers of business and its categories to identify which business / category has attracted the most reviewers (find out the highest distinct count of reviewers on business / category level). Also, analyze the temporal patterns of when reviewers submitted their reviews (you could leverage the workday, year, month, or hours to conduct the analysis) and share your findings and insights in the markdown cell. Please also include your findings and insights (visualizations) in the report."
      ],
      "metadata": {
        "id": "dR_5G8Zaf8s_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CPtSBKG_f5HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HnPCuzHYgGcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PfBldweogGQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aNQynUfagGMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RBuP3UukgGJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oLYrjbA-gGGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 1.6"
      ],
      "metadata": {
        "id": "_L0T0ZnpgNJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**\n",
        "\n",
        "As the data scientist, you are required to build a recommendation for the business by using reviews, ratings, and its categories. In this task, you need to:\n",
        "> **1.6.1** Write down your strategy of building the recommendation on business for customers in the markdown cell. You could create your own strategy or leverage the provided one here KNN on collaborative filtering. Please also include your strategy details in the report.\n",
        "\n",
        "> **1.6.2** Could you please try to implement the strategy (code) you have written down for the recommendation system? Please give detailed explanation of your code and the logic in the comments and also interpret the recommendations with examples in the markdown cell. Please also include your implementation details and results in the report."
      ],
      "metadata": {
        "id": "Bgiy9TFlgHa-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0p4_Ct_9gGDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AH1xdqusgnoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jq9xjJZjgnlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XMfQs_hvgnih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DRmVdgzWgnfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pfCpLmUBgoDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 1.7"
      ],
      "metadata": {
        "id": "jqhh3jyMgpQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**\n",
        "\n",
        "Continue work on the review data you have now, for each of the submissions of the review, you will need to explore the rating with other information:\n",
        "> **1.7.1** Build visualization to explore the relationships of the rating and business categories. Please write down your insights in the markdown cell and also include your insights and visualizations in the report.\n",
        "\n",
        "> **1.7.2** Let’s focus on the lower ratings now. Could you please find out the actual reviews on lower ratings and analyze on the reason? (You could use the common used words in lower rating reviews or design your own strategy with reasonable logic). Please also include your analysis details in the report."
      ],
      "metadata": {
        "id": "WDvPwwCvgwvI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LmgYpR8lgncf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D600awe5hANJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xtM9SUn6hAKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dFK84vj8hAGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LifwR3wthADB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6hE_livJg__n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UU8Qdv9lhA5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 1.8"
      ],
      "metadata": {
        "id": "LhrECAPihBSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**\n",
        "\n",
        "Continue to work on the submission of the reviews, we would like to focus on the reviewer level with all the reviewed business history, but before we actually conduct the programming, we will need to finish few questions for exploration:\n",
        "> **1.8.1** Check on the reviewer level reviewed business, sort the review of each business by the review time (newtime column) and then save the business name into the list variable user_business_list for each reviewer.\n",
        "\n",
        "> **1.8.2** Check on the user_business_list, could you observe some repeated business names for the same user? If so, could you remove those duplicated business names under same user? Please print out the number of element in the user_business_list for each reviewer before removing the duplicated business name and after removing the duplicated business name.\n",
        "\n",
        "> **1.8.3** Check on the user_business_list, could you find the user similarities according to their past reviewed business ? You are free to design your own strategy and give sufficient explanation in markdown cell and code implementation together. Please also include your strategy details and implementation in the report.\n",
        "\n",
        "_Hint: you might consider to use encoding for each of the business names and then calculate the difference of the users._"
      ],
      "metadata": {
        "id": "Y8nZH3f8hG1P"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2unoAhZjg_hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1GUqsdF1heKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-jHI1-6DheHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8iNr3IpLheEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2d_kklRRheCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "crh_fX60hd_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oGck5_Bkhd79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UMLtPO4Khd3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "emTibhV1he5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part II: **Submission Prediction**"
      ],
      "metadata": {
        "id": "r9COWFROhfau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 2.1"
      ],
      "metadata": {
        "id": "GVIyUwkehtPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**\n",
        "\n",
        "In this question, we will focus only on two information: total reviews per day with review time (newtime from the dataframe) to form the review volume time series. You are required to explore the review time series. There are some days not available in the review time series. Please add those days into the review time series with default number of review with the mean value of the number of review per day in the whole data (without any filtering on reviews). After that, decompose the submission review time series with addictive mode and analyses on the results to find if there is any seasonality pattern (you could leverage the M05A material from lab session with default setting in seasonal_decompose function). Please also include your analysis details and implementation in the report."
      ],
      "metadata": {
        "id": "bLDtSZP0h13P"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vYaqA5b7h1LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KEi7rra8hd0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fzmZRNi5h-GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xPGNXv9Lh-DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wl12wn3sh9_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ko7Y28m4h980"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 2.2"
      ],
      "metadata": {
        "id": "zxpNCACMh_jz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**\n",
        "\n",
        "We will try to use time series model ARIMA for forecasting the future. You need to find the best model with different parameters on ARIMA model. The parameter range for p,d,q are all from [0, 1, 2]. In total, you need to find out the best model with lowest Mean Absolute Error from 27 choices (you might need to split the time series to train and test with yourself with grid search according to the M05B material). Also, you are required to discuss with your group member on exploring the deep learning time series forecasting methods such as LSTM and RNN. Please write down your discussion around the necessary data wrangling and modeling steps (steps on how to achieve, not actual code). Also please give the reference of the deep learning time series forecasting models you are using. Please also include your discussion details and implementation in the report."
      ],
      "metadata": {
        "id": "at7fTirciEFf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "laNNt4H2iNJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qX1cmEVFiNG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kq76jriHiNDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EoCHfEM8iNAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yqbx99gKiM-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nWR5CdBMiM7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**\n",
        "\n",
        "In this question, you are provided with the PDF file by Universities Australia via Indigenous Strategy annual report. You are required to critically analyze this report using your data science skills.\n",
        "> **Data Extraction** Carefully review the PDF and identify all relevant quantitative data, tables, and figures that can be extracted or digitized; Present any extracted data in a structured format (e.g., CSV, Excel table, or DataFrame);\n",
        "\n",
        "> **Data Analysis** Utilize your data analytics skills to discover common patterns or trends from the report; Where possible, compare trends over multiple years, between institutions, or across different Indigenous strategy metrics.\n",
        "\n",
        "> **Insights** Provide a clear and concise summary of the main patterns, trends, or correlations discovered from your analysis; Interpret what these findings reveal about the progress and challenges of Indigenous strategies in Australian universities.\n",
        "\n",
        "_You may use any data analytics tools or libraries you are comfortable with. All steps, from extraction to insights, should be clearly documented in your SIT742Task2Report.pdf, and source code should be in SIT742Task2Code.ipynb._"
      ],
      "metadata": {
        "id": "84Pr3udziN9D"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3YT0t8Ysh95z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YEsRlDnGjH08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5kLEWGI8jHx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vPd31AwRjHvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OJ-NB_hxjHr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ukjZ54sgjHpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KIfmqAgjjHmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q9OQr7XrjHix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part III: **Optional: Questionnaire on Integrating Indigenous Perspectives into DS Education**"
      ],
      "metadata": {
        "id": "n2Rrq-MjjGY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** This part of the assignment is **optional** and carries **no mark**.\n",
        "\n",
        "In modern data-driven environments, collaboration often involves individuals from diverse cultural and social backgrounds. As part of our ongoing efforts to develop inclusive and socially responsible unit, we are exploring ways to meaningfully integrate Australian Indigenous perspectives into Data Science education, specifically in the context of the unit SIT742: Modern Data Science. We invite you to share your thoughts and feedback on this important topic. Your input will help us improve the quality and inclusiveness of both the unit and its associated learning materials.\n",
        "If you are willing to assist, please consider completing a short questionnaire titled Integrating Indigenous Perspectives into Data Science Education, which can be accessed at the following link:\n",
        "- [POST-Survey Questionnaire](https://researchsurveys.deakin.edu.au/jfe/form/SV_3dZpMmkbdjsKkaq)\n",
        "\n",
        "(Please interpret its references to “ICT” as also including Data Science.)"
      ],
      "metadata": {
        "id": "qSDq3UjxjGV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Related Information\n",
        "**Human Research Ethics Application ID:** 2025/HE000518 Approval Date: 28/04/2025 Estimated Time to Complete: Approximately 10 minutes\n",
        "\n",
        "**Confidentiality:** All responses are strictly confidential and will be used solely for research and educational improvement purposes.\n",
        "\n",
        "**University Policy** Deakin Indigenous Strategy 2023-2028"
      ],
      "metadata": {
        "id": "ypcSFUTjjGTX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D0Th5XH-lliC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}